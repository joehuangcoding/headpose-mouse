{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T07:07:42.887847Z","iopub.status.busy":"2024-01-10T07:07:42.887068Z","iopub.status.idle":"2024-01-10T07:07:54.794583Z","shell.execute_reply":"2024-01-10T07:07:54.793466Z","shell.execute_reply.started":"2024-01-10T07:07:42.887809Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow==2.10 in /opt/conda/lib/python3.10/site-packages (2.10.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (1.51.1)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (3.9.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (2.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (1.1.2)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (1.24.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (21.3)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (3.19.6)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (68.1.2)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (1.16.0)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (2.10.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (0.34.0)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (2.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10) (1.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.10) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.22.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.10) (3.0.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.2.7)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.9)\n","Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (1.26.15)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.1.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.2.2)\n"]}],"source":["!pip install tensorflow==2.10"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-10T07:07:54.797931Z","iopub.status.busy":"2024-01-10T07:07:54.797036Z","iopub.status.idle":"2024-01-10T07:08:21.056486Z","shell.execute_reply":"2024-01-10T07:08:21.055683Z","shell.execute_reply.started":"2024-01-10T07:07:54.797886Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 65340 images belonging to 2 classes.\n","Found 16335 images belonging to 2 classes.\n","Found 3223 images belonging to 2 classes.\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Define your data directories\n","train_data_directory = \"/kaggle/input/mrl-eye-dataset/data/train\"\n","test_data_directory = \"/kaggle/input/mrl-eye-dataset/data/test\"\n","\n","# Set the image size and batch size\n","img_size = (30, 30)\n","batch_size = 32\n","\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2,  # Assuming 80% training and 20% validation\n","    rotation_range=20,  # Additional augmentation for diversity\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    brightness_range=[0.8, 1.2],\n","    fill_mode='nearest'\n",")\n","\n","# Generate the training dataset\n","train_generator = datagen.flow_from_directory(\n","    train_data_directory,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    color_mode='grayscale',\n","    class_mode='binary',  # 'binary' for binary classification\n","    subset='training'  # Use 'training' for training dataset\n",")\n","\n","# Generate the validation dataset\n","validation_generator = datagen.flow_from_directory(\n","    train_data_directory,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    color_mode='grayscale',\n","    class_mode='binary',\n","    subset='validation',\n","    shuffle=False\n",")\n","\n","# Generate the test dataset\n","test_generator = datagen.flow_from_directory(\n","    test_data_directory,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    color_mode='grayscale',\n","    class_mode='binary',\n","    shuffle=False  # Set to False to maintain the order for evaluation\n",")\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T07:08:21.057985Z","iopub.status.busy":"2024-01-10T07:08:21.057689Z","iopub.status.idle":"2024-01-10T07:08:21.158565Z","shell.execute_reply":"2024-01-10T07:08:21.157603Z","shell.execute_reply.started":"2024-01-10T07:08:21.057959Z"},"trusted":true},"outputs":[],"source":["\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.optimizers import Adam\n","# Build your CNN model using TensorFlow's Keras API\n","model = tf.keras.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 1)),\n","    layers.MaxPooling2D(2, 2),\n","    layers.Dropout(0.25),\n","    \n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D(2, 2),\n","    layers.Dropout(0.25),\n","    \n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D(2, 2),\n","    layers.Dropout(0.25),\n","    \n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    \n","    layers.Dense(1, activation='sigmoid')\n","])\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T07:08:21.160865Z","iopub.status.busy":"2024-01-10T07:08:21.160578Z","iopub.status.idle":"2024-01-10T07:08:21.178851Z","shell.execute_reply":"2024-01-10T07:08:21.178136Z","shell.execute_reply.started":"2024-01-10T07:08:21.160841Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","loss = 'binary_crossentropy'\n","metrics = ['accuracy']\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T07:08:21.180313Z","iopub.status.busy":"2024-01-10T07:08:21.179973Z","iopub.status.idle":"2024-01-10T08:00:20.999241Z","shell.execute_reply":"2024-01-10T08:00:20.998263Z","shell.execute_reply.started":"2024-01-10T07:08:21.180286Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8364\n","Epoch 1: val_loss improved from inf to 0.24303, saving model to eye_blink.h5\n","2041/2041 [==============================] - 591s 289ms/step - loss: 0.3441 - accuracy: 0.8364 - val_loss: 0.2430 - val_accuracy: 0.9119\n","Epoch 2/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9349\n","Epoch 2: val_loss improved from 0.24303 to 0.20303, saving model to eye_blink.h5\n","2041/2041 [==============================] - 153s 75ms/step - loss: 0.1677 - accuracy: 0.9349 - val_loss: 0.2030 - val_accuracy: 0.9171\n","Epoch 3/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.9444\n","Epoch 3: val_loss improved from 0.20303 to 0.17332, saving model to eye_blink.h5\n","2041/2041 [==============================] - 146s 72ms/step - loss: 0.1444 - accuracy: 0.9444 - val_loss: 0.1733 - val_accuracy: 0.9297\n","Epoch 4/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9516\n","Epoch 4: val_loss did not improve from 0.17332\n","2041/2041 [==============================] - 140s 69ms/step - loss: 0.1265 - accuracy: 0.9516 - val_loss: 0.1927 - val_accuracy: 0.9254\n","Epoch 5/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9542\n","Epoch 5: val_loss did not improve from 0.17332\n","2041/2041 [==============================] - 129s 63ms/step - loss: 0.1213 - accuracy: 0.9542 - val_loss: 0.1954 - val_accuracy: 0.9198\n","Epoch 6/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9567\n","Epoch 6: val_loss did not improve from 0.17332\n","2041/2041 [==============================] - 140s 69ms/step - loss: 0.1134 - accuracy: 0.9567 - val_loss: 0.1875 - val_accuracy: 0.9257\n","Epoch 7/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9584\n","Epoch 7: val_loss did not improve from 0.17332\n","2041/2041 [==============================] - 140s 69ms/step - loss: 0.1120 - accuracy: 0.9584 - val_loss: 0.2129 - val_accuracy: 0.9151\n","Epoch 8/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9607\n","Epoch 8: val_loss improved from 0.17332 to 0.15507, saving model to eye_blink.h5\n","2041/2041 [==============================] - 182s 89ms/step - loss: 0.1045 - accuracy: 0.9607 - val_loss: 0.1551 - val_accuracy: 0.9351\n","Epoch 9/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9626\n","Epoch 9: val_loss improved from 0.15507 to 0.13910, saving model to eye_blink.h5\n","2041/2041 [==============================] - 149s 73ms/step - loss: 0.1039 - accuracy: 0.9626 - val_loss: 0.1391 - val_accuracy: 0.9403\n","Epoch 10/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9626\n","Epoch 10: val_loss did not improve from 0.13910\n","2041/2041 [==============================] - 120s 59ms/step - loss: 0.1012 - accuracy: 0.9626 - val_loss: 0.1698 - val_accuracy: 0.9316\n","Epoch 11/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9633\n","Epoch 11: val_loss did not improve from 0.13910\n","2041/2041 [==============================] - 121s 59ms/step - loss: 0.0985 - accuracy: 0.9633 - val_loss: 0.1697 - val_accuracy: 0.9333\n","Epoch 12/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9654\n","Epoch 12: val_loss did not improve from 0.13910\n","2041/2041 [==============================] - 124s 61ms/step - loss: 0.0953 - accuracy: 0.9654 - val_loss: 0.1416 - val_accuracy: 0.9461\n","Epoch 13/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9663\n","Epoch 13: val_loss improved from 0.13910 to 0.13051, saving model to eye_blink.h5\n","2041/2041 [==============================] - 122s 60ms/step - loss: 0.0913 - accuracy: 0.9663 - val_loss: 0.1305 - val_accuracy: 0.9504\n","Epoch 14/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9666\n","Epoch 14: val_loss did not improve from 0.13051\n","2041/2041 [==============================] - 124s 61ms/step - loss: 0.0917 - accuracy: 0.9666 - val_loss: 0.1419 - val_accuracy: 0.9487\n","Epoch 15/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9671\n","Epoch 15: val_loss did not improve from 0.13051\n","2041/2041 [==============================] - 124s 61ms/step - loss: 0.0912 - accuracy: 0.9671 - val_loss: 0.1798 - val_accuracy: 0.9223\n","Epoch 16/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9684\n","Epoch 16: val_loss did not improve from 0.13051\n","2041/2041 [==============================] - 117s 57ms/step - loss: 0.0881 - accuracy: 0.9684 - val_loss: 0.1607 - val_accuracy: 0.9328\n","Epoch 17/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.9689\n","Epoch 17: val_loss did not improve from 0.13051\n","2041/2041 [==============================] - 117s 57ms/step - loss: 0.0870 - accuracy: 0.9689 - val_loss: 0.2146 - val_accuracy: 0.9309\n","Epoch 18/20\n","2041/2041 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9685\n","Epoch 18: val_loss did not improve from 0.13051\n","2041/2041 [==============================] - 116s 57ms/step - loss: 0.0864 - accuracy: 0.9685 - val_loss: 0.1571 - val_accuracy: 0.9360\n","Epoch 19/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9691\n","Epoch 19: val_loss did not improve from 0.13051\n","2041/2041 [==============================] - 120s 59ms/step - loss: 0.0871 - accuracy: 0.9691 - val_loss: 0.1454 - val_accuracy: 0.9426\n","Epoch 20/20\n","2040/2041 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9698\n","Epoch 20: val_loss improved from 0.13051 to 0.12958, saving model to eye_blink.h5\n","2041/2041 [==============================] - 118s 58ms/step - loss: 0.0842 - accuracy: 0.9698 - val_loss: 0.1296 - val_accuracy: 0.9478\n","100/100 [==============================] - 25s 248ms/step - loss: 0.1317 - accuracy: 0.9525\n","Test Accuracy: 95.25%\n"]}],"source":["# Define a ModelCheckpoint callback to save the model on each batch\n","checkpoint_callback = ModelCheckpoint(\n","    \"eye_blink.h5\",  # Specify the path to save the model\n","    save_freq='epoch',  # Save on each batch\n","    save_best_only=True,  # Save every model\n","    save_weights_only=False,  # Save the entire model\n","    verbose=1\n",")\n","# Train your model\n","model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=20,  # Adjust as needed\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // batch_size,\n","    callbacks=[checkpoint_callback]\n",")\n","\n","# Evaluate your model on the test set\n","test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n","print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()\n","\n","# Assuming y_true, y_pred_probs, and test_generator are defined\n","y_true = test_generator.classes\n","y_pred_probs = model.predict(test_generator)\n","y_pred = (y_pred_probs >= 0.5).astype(int)\n","\n","# Compute and print the confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_true, y_pred)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Print classification report\n","print(\"Classification Report:\")\n","print(classification_report(y_true, y_pred))\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n","            xticklabels=test_generator.class_indices.keys(),\n","            yticklabels=test_generator.class_indices.keys())\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T08:00:21.006956Z","iopub.status.busy":"2024-01-10T08:00:21.006719Z","iopub.status.idle":"2024-01-10T08:00:21.708577Z","shell.execute_reply":"2024-01-10T08:00:21.707607Z","shell.execute_reply.started":"2024-01-10T08:00:21.006934Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 130ms/step\n","[[1.1706733e-06]]\n","eye close detected.\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to preprocess an input image\n","def preprocess_image(image_path, target_size=(30, 30), grayscale=True):\n","    # Read the image\n","    image = cv2.imread(image_path)\n","\n","    # Resize the image to the target size\n","    image = cv2.resize(image, target_size)\n","    if grayscale:\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    # Convert to float32 and normalize to the range [0, 1]\n","    image = image.astype(np.float32) / 255.0\n","\n","    return image\n","# Load the model\n","model = load_model('eye_blink.h5')\n","# Load an example image\n","example_image_path = '/kaggle/input/mrl-eye-dataset/data/test/close eyes/s0002_00001_0_0_0_0_0_01.png'\n","#example_image_path = '/kaggle/input/mrl-eye-dataset/data/test/open eyes/s0001_01846_0_0_1_0_0_01.png'\n","\n","def cv2_imshow(image, title=\"Image\"):\n","    # Convert BGR image to RGB\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    \n","    # Display using matplotlib\n","    plt.imshow(image_rgb)\n","    plt.title(title)\n","    plt.axis('off')\n","    plt.show()\n","    \n","\n","\n","input_image = preprocess_image(example_image_path, grayscale=True)\n","cv2_imshow(input_image, \"test\")\n","# Expand dimensions to match the model input shape\n","input_image = np.expand_dims(input_image, axis=0)\n","\n","# Make a prediction\n","prediction = model.predict(input_image)\n","\n","print(prediction)\n","\n","# Convert the prediction to a binary result (blink or not)\n","is_eye_open = prediction[0, 0] > 0.5\n","\n","# Print the result\n","if is_eye_open:\n","    print(\"eye open detected!\")\n","else:\n","    print(\"eye close detected.\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1958152,"sourceId":3368350,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
